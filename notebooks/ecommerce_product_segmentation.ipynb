{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ecommerce_product_segmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4n1XwCjozUP",
        "outputId": "ebdb6fa1-be9b-4a32-9c13-c82f72b00bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "import torchvision.models as models\n",
        "# opencv is pre-installed on colab\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from shutil import copyfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101 False\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIMX1Zw0ug8e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juLyBpsbqH-G"
      },
      "source": [
        "Image segmentation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9txbi3OyqVM9"
      },
      "source": [
        "path_trainValTest = \"/content/drive/My Drive/aim/vision-project/segmentation_dataset/confidence>0.75/trainValTest/\"\n",
        "# Load dataset\n",
        "with open(path_trainValTest + 'ecommerce-segmentation-dataset-filename.json') as json_file:\n",
        "    dataset = json.load(json_file)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAjJ3Uev1PB_"
      },
      "source": [
        "path_trainValTest = \"/content/drive/My Drive/aim/vision-project/segmentation_dataset/confidence>0.75/trainValTest/\"\n",
        "\n",
        "# Load dataset\n",
        "with open(path_trainValTest + 'ecommerce-segmentation-dataset-filename.json') as json_file:\n",
        "    dataset = json.load(json_file)\n",
        "\n",
        "def load_image_from_filename(dataset):\n",
        "  images = []\n",
        "  masks = []\n",
        "  for i in range(len(dataset)):\n",
        "    if i%25==0:\n",
        "      print(str(i) + \"/\" + str(len(dataset)))\n",
        "    raw_image = tf.keras.preprocessing.image.load_img(dataset[i][\"image\"])\n",
        "    arr_image = keras.preprocessing.image.img_to_array(raw_image)\n",
        "    images.append(arr_image)\n",
        "    #dataset[i][\"image\"] = tf.convert_to_tensor(arr_image)\n",
        "\n",
        "    #raw_mask = tf.keras.preprocessing.image.load_img(dataset[i][\"segmentation_mask\"])\n",
        "    #arr_mask = keras.preprocessing.image.img_to_array(raw_mask)\n",
        "    csv_arr_mask = np.loadtxt(dataset[i][\"segmentation_mask\"], delimiter=',')\n",
        "    arr_mask = np.zeros((csv_arr_mask.shape[0],csv_arr_mask.shape[1],1))\n",
        "    arr_mask[:,:,0] = csv_arr_mask\n",
        "    masks.append(arr_mask)\n",
        "    #dataset[i][\"segmentation_mask\"] = tf.convert_to_tensor(arr_image)\n",
        "\n",
        "  return images, masks\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  #input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "\n",
        "def load_image_test(img, mask):\n",
        "  # Image\n",
        "  input_image = tf.image.resize(img, (128, 128))\n",
        "  # Mask\n",
        "  input_mask = tf.image.resize(mask, (128, 128))\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "  return input_image, input_mask\n",
        "\n",
        "#train_images, train_masks = load_image_from_filename(dataset[\"train\"])\n",
        "#val_images, val_masks = load_image_from_filename(dataset[\"val\"])\n",
        "#test_images, test_masks = load_image_from_filename(dataset[\"test\"])\n",
        "\n",
        "#test = tf.data.Dataset.from_tensor_slices((test_images, test_masks))\n",
        "#test = test.map(load_image_test)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05wxmQV6zCkK"
      },
      "source": [
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'background', 'couch', 'chair', 'bed', 'vase', 'bowl', 'cup',\n",
        "    'wine-glass', 'potted-plant'\n",
        "])"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSOehRZzq8gD",
        "outputId": "c4a00957-ba57-4c35-9a03-1fcc6d41dc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(dataset[\"test\"])"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_UE1KovpzFd"
      },
      "source": [
        "Get results with pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn8386jCxXfX"
      },
      "source": [
        "def preprocess_image(input_image):\n",
        "  input_image = tf.keras.preprocessing.image.load_img(input_image)\n",
        "  input_image = keras.preprocessing.image.img_to_array(input_image)\n",
        "  #input_image = tf.image.resize(arr_image, (128, 128))\n",
        "  #input_image = input_image/255\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  return input_image\n",
        "\n",
        "def preprocess_mask(input_mask):\n",
        "  #input_mask = tf.image.resize(input_mask, (128, 128))\n",
        "  return input_mask\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]\n",
        "\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    #raw_image = tf.keras.preprocessing.image.load_img(display_list[i])\n",
        "    #arr_image = keras.preprocessing.image.img_to_array(raw_image)\n",
        "    #plt.imshow(tf.keras.preprocessing.image.array_to_img(arr_image))\n",
        "    #plt.imshow(raw_image)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slwl0LQdQHlB"
      },
      "source": [
        "model_input_images = []\n",
        "expected_masks = []\n",
        "\n",
        "for test_image_id in range(10): #range(len(dataset[\"test\"][0])):\n",
        "    # Load and preprocess image\n",
        "    input_image = preprocess_image(dataset[\"test\"][test_image_id][\"image\"])\n",
        "    # Channel first\n",
        "    input_image = torch.tensor(input_image.numpy()).permute(2,0,1)\n",
        "    model_input_images.append(input_image)\n",
        "\n",
        "    # Load and resize expcted mask\n",
        "    expected_mask = preprocess_mask(test_masks[test_image_id])\n",
        "    expected_masks.append(expected_mask)"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRo0OEI7shZG"
      },
      "source": [
        "# Faster Mask R-CNN model with a ResNet-50-FPN backbone.\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# To get model evaulation time\n",
        "def get_model_evaluation_time(model_input_images):\n",
        "  \"\"\"\n",
        "  for input_image in model_input_images:\n",
        "    # Get model prediction\n",
        "    predictions = model([input_image])\n",
        "  \"\"\"\n",
        "  predictions = model(model_input_images)"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ9hCna8GOG_",
        "outputId": "687cb6bf-0ad0-4d50-8def-76ea10cf27a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%time get_model_evaluation_time(model_input_images)\n",
        "# %prun get_model_evaluation_time(model_input_images)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 2s, sys: 6.96 s, total: 1min 9s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2IRgFxjLYMV",
        "outputId": "6a2e7e3e-9faf-4e88-f210-778f88f61b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mean IoU\n",
        "m = tf.keras.metrics.MeanIoU(num_classes=len(LABEL_NAMES))\n",
        "m.reset_states()\n",
        "\n",
        "# To get model evaulation time\n",
        "for test_image_id in range(len(model_input_images)):\n",
        "\n",
        "  if test_image_id % 10 == 0:\n",
        "    print(test_image_id)\n",
        "\n",
        "  \"\"\"\n",
        "  # Load and preprocess image\n",
        "  input_image = preprocess_image(dataset[\"test\"][test_image_id][\"image\"])\n",
        "  # Channel first\n",
        "  input_image = torch.tensor(input_image.numpy()).permute(2,0,1)\n",
        "\n",
        "  # Load and resize expcted mask\n",
        "  expected_mask = preprocess_mask(test_masks[test_image_id])\n",
        "  \"\"\"\n",
        "\n",
        "  input_image = model_input_images[test_image_id]\n",
        "  expected_mask = expected_masks[test_image_id]\n",
        "\n",
        "  # Get model prediction\n",
        "  predictions = model([input_image])\n",
        "  predicted_mask = predictions[0][\"masks\"][0].permute(1,2,0).detach().numpy()\n",
        "\n",
        "  # Threshold soft mask to get 0, 1 labels\n",
        "  hard_mask = (predicted_mask>0.5).astype(int)\n",
        "  # Convert binary label to corresponding label category\n",
        "  predicted_category = COCO_INSTANCE_CATEGORY_NAMES[predictions[0][\"labels\"][0]]\n",
        "  label_id = np.where(LABEL_NAMES==predicted_category)[0][0]\n",
        "  hard_mask[hard_mask==1] = label_id\n",
        "\n",
        "  # Plot image, mask and predicted mask\n",
        "  #sample_image, sample_mask = load_image_test(test_images[test_image_id], test_masks[test_image_id])\n",
        "  #display([sample_image, expected_mask, hard_mask])\n",
        "\n",
        "  # Compute mean IoU\n",
        "  m.update_state(hard_mask, expected_mask)\n",
        "\n",
        "m.result().numpy()"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCMdARzEG626"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKihv2GODRSh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ZpKfsrDRM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdO3fJvKDRLI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKjm_kUeDPB6"
      },
      "source": [
        "Etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LohajixU8Nmz",
        "outputId": "f159eafd-7d33-4050-a7bd-3beb58a1f98b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hard_mask = (predicted_mask>0.5).astype(int)\n",
        "\n",
        "predicted_category = COCO_INSTANCE_CATEGORY_NAMES[predictions[0][\"labels\"][0]]\n",
        "label_id = np.where(LABEL_NAMES==predicted_category)[0][0]\n",
        "hard_mask[hard_mask==1] = label_id\n",
        "\n",
        "t = hard_mask.tolist() #.unique()\n",
        "flat_list = [item for sublist in t for item in sublist]\n",
        "flat_list = [item for sublist in flat_list for item in sublist]\n",
        "np.unique(flat_list)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skdl1ZpSBVPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}